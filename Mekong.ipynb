{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mekong River Study Area\n",
    "\n",
    "This is the annotated version of the notebook created by Sven-Arne Quist to try the CoastSat algorithm on a study area in the Mekong River. \n",
    "More background on the study area can be found here: https://www.nature.com/articles/s41598-019-53804-z. In addition, we have bathymetry data available for this research area, which we can use during the development of this product. \n",
    "\n",
    "This notebook is created for reading purposes. **You don't need to execute this notebook** (unless you have 8 hours spare time). \n",
    "> The notebook contains direct quotes from an example notebook provided in the CoastSat repo: https://github.com/kvos/CoastSat/blob/master/example_jupyter.ipynb.\n",
    "> The original algorithm was published in: \n",
    ">> Vos K., Splinter K.D., Harley M.D., Simmons J.A., Turner I.L. (2019). CoastSat: a Google Earth Engine-enabled Python toolkit to extract shorelines from publicly available satellite imagery. Environmental Modelling and Software. 122, 104528. https://doi.org/10.1016/j.envsoft.2019.104528\n",
    "\n",
    "My comments are provided in normal text. \n",
    "Ideas about **tweaks** to add at a particular place in the model are highligthed in bold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Initial settings\n",
    "> \n",
    "> Refer to the **Installation** section of the README for instructions on how to install the Python packages necessary to run the software, including Google Earth Engine Python API. If that step has been completed correctly, the following packages should be imported without any problem.\n",
    "\n",
    "I added geopandas in there for the compatibility with polygon files to define the area of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from coastsat import SDS_download, SDS_preprocess, SDS_shoreline, SDS_tools, SDS_transects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load area of interest into \"coords\". This is a change made by me to allow for uploading of geojson files to the algorithm. The code below unpacks the coordinates into a list of lists called \"coords\". \n",
    "\n",
    "**Possible tweaks**: \n",
    "1. Allowing for kml files that can be user defined in Google Earth and read into the algorithm. \n",
    "2. Or adding an interactive webmapping tool that allows the user to draw polygons of the area of interest and automatically upload them to the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[105.7683639, 10.3287573], [105.7676773, 10.2517387], [105.9413986, 10.2497117], [105.9393386, 10.3250419], [105.7683639, 10.3287573]]]\n"
     ]
    }
   ],
   "source": [
    "aoi_poly = gpd.read_file(\"Mekong_StudyArea.geojson\")\n",
    "g = [i for i in aoi_poly.geometry]\n",
    "x,y = g[0].exterior.coords.xy\n",
    "coords = np.dstack((x,y)).tolist()\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Retrieval of the images from GEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">Define the region of interest (`polygon`), the date range (`dates`) and the satellite missions (`sat_list`) from which you wish to retrieve the satellite images. The images will be cropped on the Google Earth Engine server and only the region of interest will be downloaded as a .tif file. The files will stored in the directory defined in `filepath`. \n",
    ">\n",
    ">Make sure the area of your ROI is smaller than 100 km2 (if larger split it into smaller ROIs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the parameters are filled in by me already for the Mekong River example.  \n",
    "\n",
    "**Possible tweaks**: within the \"dates\" variable, the upper bound of the time series (most recent date) can be automatically updated by the system date obtained from the computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# region of interest (longitude, latitude)\n",
    "\n",
    "polygon = coords \n",
    "# date range\n",
    "dates = ['1985-01-01', '2020-04-01']\n",
    "# satellite missions\n",
    "sat_list = ['L5', 'L7', 'L8', 'S2']\n",
    "# name of the site\n",
    "sitename = 'MEKONG'\n",
    "# directory where the data will be stored\n",
    "filepath = os.path.join(os.getcwd(), 'data')\n",
    "# put all the inputs into a dictionnary\n",
    "inputs = {'polygon': polygon, 'dates': dates, 'sat_list': sat_list, 'sitename': sitename, 'filepath':filepath}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The function `SDS_download.check_images_available(inputs)` will print the number of images available for your inputs. The Landsat images are divided in Tier 1 and Tier 2, only Tier 1 images can be used for time-series analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No change needed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images available between 1985-01-01 and 2020-04-01:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  L5: 223 images\n",
      "  L7: 232 images\n",
      "  L8: 126 images\n",
      "  S2: 525 images\n",
      "  Total: 1106 images\n",
      "- In Landsat Tier 2:\n",
      "  L5: 132 images\n",
      "  L7: 63 images\n",
      "  L8: 26 images\n",
      "  Total: 221 images\n"
     ]
    }
   ],
   "source": [
    "# before downloading the images, check how many images are available for your inputs\n",
    "SDS_download.check_images_available(inputs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> \"The function `SDS_download.retrieve_images(inputs)` retrives the satellite images from Google Earth Engine.\n",
    ">\n",
    "> By default, only Landsat Tier 1 and Sentinel-2 Level-1C are downloaded. \n",
    ">\n",
    "> In case you need to access Tier 2 images for qualitative analysis, you need to set `inputs['include_T2'] = True` before calling `retrieve_images`.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how long it took to download the image library defined above: it took 3 hours. I'm not sure whether we need Tier-2 images as well, because it will only increase the download and analysis time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images available between 1985-01-01 and 2020-04-01:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "  L5: 223 images\n",
      "  L7: 232 images\n",
      "  L8: 126 images\n",
      "  S2: 525 images\n",
      "  Total: 1106 images\n",
      "- In Landsat Tier 2:\n",
      "  L5: 132 images\n",
      "  L7: 63 images\n",
      "  L8: 26 images\n",
      "  Total: 221 images\n",
      "\n",
      "Downloading images:\n",
      "L5: 223 images\n",
      "3%"
     ]
    }
   ],
   "source": [
    "# inputs['include_T2'] = True\n",
    "metadata = SDS_download.retrieve_images(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \" **If you have already retrieved the images**, just load the metadata file by only running the section below\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = SDS_download.get_metadata(inputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Shoreline Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This section maps the position of the shoreline on the satellite images. The user can define the cloud threhold (`cloud_thresh`) and select the spatial reference system in which to output the coordinates of the mapped shorelines (`output_epsg`). See http://spatialreference.org/ to find the EPSG number corresponding to your local coordinate system. Make sure that your are using cartesian coordinates and not spherical coordinates (lat,lon) like WGS84. \n",
    ">\n",
    ">To quality control each shoreline detection and manually validate the mapped shorelines, the user has the option to set the parameter `check_detection` to **True**. To save a figure for each mapped shoreline set `save_figure` to **True**. \n",
    ">\n",
    ">The other parameters are for advanced users only and are described in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cloud_thresh** Here we might tune up the cloud threshold to reduce the data volume and get possibly get a more accurate database. However, this might come at the expense of the temporal dimension of the time series. \n",
    "- **check_detection** This should always set to False, otherwise you are forced to manually judge every image in the time series.\n",
    "- **save_figure**: **tweak needed here** Currently, the model saves an image of the classification output (with classes of 'water', 'sand', and 'whitewater') and the shoreline on the model. We should adjust the model in such a way that it discards extracting the shoreline alltogether, and in stead just saves the output of the classified images. \n",
    "- advanced settings: I downtuned the 'min_beach_area' by a factor of 10.  \n",
    "  **Tweak needed here**: I think we might discard the beach detection part of the algorithm all togehter, or add a functionality were we can specifiy whether the river bank is sandy or not. This boolean will then activate the sand detection algorithm, and take up analysis from there according to the regular CoastSat proceedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = { \n",
    "    # general parameters:\n",
    "    'cloud_thresh': 0.5,        # threshold on maximum cloud cover\n",
    "    'output_epsg': 28356,       # epsg code of spatial reference system desired for the output   \n",
    "    # quality control:\n",
    "    'check_detection': False,    # if True, shows each shoreline detection to the user for validation\n",
    "    'save_figure': True,        # if True, saves a figure showing the mapped shoreline for each image\n",
    "    'color_style': False,       # if True, saves figure as true color image. If False, saves figure as false color image. \n",
    "    # add the inputs defined previously\n",
    "    'inputs': inputs,\n",
    "    # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "    'min_beach_area': 450,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "    'buffer_size': 150,         # radius (in metres) of the buffer around sandy pixels considered in the shoreline detection\n",
    "    'min_length_sl': 200,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "    'cloud_mask_issue': False,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    "    'sand_color': 'default',    # 'default', 'dark' (for grey/black sand beaches) or 'bright' (for white sand beaches)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### [OPTIONAL] Save .jpg of the satellite images \n",
    "> Saves .jpg files of the preprocessed satellite images (cloud masking + pansharpening/down-sampling) under *./data/sitename/jpeg_files\\preprocessed*\n",
    "\n",
    "**Tweak** I don't think we need this part for the final product, it just adds unnecessary data and time in the analysis. But it is handy to look at during the development phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satellite images saved as .jpg in C:\\Users\\Administrator\\Downloads\\CoastSat-master\\CoastSat-master\\data\\MEKONG\\jpg_files\\preprocessed\n"
     ]
    }
   ],
   "source": [
    "# save jpeg of processed satellite image\n",
    "SDS_preprocess.save_jpg(metadata, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### [OPTIONAL] Digitize a reference shoreline\n",
    "Creates a reference shoreline which helps to identify outliers and false detections. The reference shoreline is manually digitised by the user on one of the images. The parameter `max_dist_ref` defines the maximum distance from the reference shoreline (in metres) at which a valid detected shoreline can be. If you think that the default value of 100 m will not capture the full shoreline variability of your site, increase this value to an appropriate distance.\n",
    "\n",
    "Here I digitzed the northern river bank to help the algorithm on its way. \n",
    "We may or may not need this proceedure depending on whether the riverbank is sandy or not. In the end, the analysis will look completely different for non-sandy river banks, so then this feature will not be necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference shoreline already exists and was loaded\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "settings['reference_shoreline'] = SDS_preprocess.get_reference_sl(metadata, settings)\n",
    "settings['max_dist_ref'] = 100 # max distance (in meters) allowed from the reference shoreline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Batch shoreline detection\n",
    ">Extracts the 2D shorelines from the images in the spatial reference system specified by the user in `'output_epsg'`. The mapped shorelines are saved into `output.pkl` (under *./data/sitename*) and `output.geojson` (to be used in a GIS software).\n",
    ">\n",
    ">If you see that the sand pixels on the images are not being identified, change the parameter `sand_color` from `default` to `dark` or `bright` depending on the color of your beach. \n",
    "\n",
    "To get an idea of how long this takes: it took me 5 and a half hours to run this. This is by far the most heavy processing part of the algorithm, but we may not use it in the end for non-sandy river banks. In stead we should develop something else (to be discussed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping shorelines:\n",
      "L5:   100%\n",
      "L7:   100%\n",
      "L8:   100%\n",
      "S2:   75%Could not map shoreline for this image: 2019-05-21-03-35-15_S2_MEKONG_10m.tif\n",
      "S2:   100%\n"
     ]
    }
   ],
   "source": [
    "#moment of truth\n",
    "%matplotlib qt\n",
    "output = SDS_shoreline.extract_shorelines(metadata, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Simple plot of the mapped shorelines. The coordinates are stored in the output dictionnary together with the exact dates in UTC time, the georeferencing accuracy and the cloud cover.\n",
    "\n",
    "In this plot you can see all the shorelines as a shape in a graph. In this way you can compare them against each other and spot outliers. I did not find this plot very useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output['shorelines'])):\n",
    "    sl = output['shorelines'][i]\n",
    "    date = output['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.', label=date.strftime('%d-%m-%Y'))\n",
    "plt.legend()\n",
    "mng = plt.get_current_fig_manager()                                         \n",
    "mng.window.showMaximized()    \n",
    "fig.set_size_inches([15.76,  8.52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 3. Shoreline analysis\n",
    ">\n",
    "> In this section we show how to compute time-series of cross-shore distance along user-defined shore-normal transects.\n",
    ">\n",
    "> **If you have already mapped the shorelines**, just load the output file (`output.pkl`) by running the section below\n",
    "\n",
    "**Important:** \n",
    "Here is the most promising section of the code. Once we classified the river on every image after the download phase, we can measure the width of the river in a time series. The principle highligthed over here is very similar, although you look at the coastline change in this example. \n",
    "\n",
    "**Tweak** We should develop an automated proceedure to make cross sections for the river that can be analyzed by this time series method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(inputs['filepath'], sitename)\n",
    "with open(os.path.join(filepath, sitename + '_output' + '.pkl'), 'rb') as f:\n",
    "    output = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There are 3 options to define the coordinates of the shore-normal transects:\n",
    ">\n",
    "> **Option 1**: the user can interactively draw the shore-normal transects along the beach by calling:\n",
    "\n",
    "I implemented option one over here because it was quick and easy. We should develop a better method to place transects across the river to measure the width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transect locations saved in C:\\Users\\Administrator\\Downloads\\CoastSat-master\\CoastSat-master\\data\\MEKONG\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "transects = SDS_transects.draw_transects(output, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Option 2**: the user can load the transect coordinates (make sure the spatial reference system is the same as defined previously by the parameter *output_epsg*) from a .geojson file by calling:\n",
    "\n",
    "Just listed here for completeness, not implemented here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_file = os.path.join(os.getcwd(), 'examples', 'NARRA_transects.geojson')\n",
    "transects = SDS_tools.transects_from_geojson(geojson_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Option 3**: manually provide the coordinates of the transects as shown in the example below:\n",
    "\n",
    "Probably in the direction of the most optimal way to spread the transects over the river area. Maybe we can automatically spread the crossections over the area with defined regular intervals. Again, not implemented here but listed for completeness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transects = dict([])\n",
    "transects['Transect 1'] = np.array([[342836, 6269215], [343315, 6269071]])\n",
    "transects['Transect 2'] = np.array([[342482, 6268466], [342958, 6268310]])\n",
    "transects['Transect 3'] = np.array([[342185, 6267650], [342685, 6267641]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, intersect the transects with the 2D shorelines to obtain time-series of cross-shore distance.\n",
    ">\n",
    ">The time-series of shoreline change for each transect are saved in a .csv file in the data folder (all dates are in UTC time). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-series of the shoreline change along the transects saved as:\n",
      "C:\\Users\\Administrator\\Downloads\\CoastSat-master\\CoastSat-master\\data\\MEKONG\\transect_time_series.csv\n"
     ]
    }
   ],
   "source": [
    "# defines the along-shore distance over which to consider shoreline points to compute the median intersection (robust to outliers)\n",
    "settings['along_dist'] = 25 \n",
    "cross_distance = SDS_transects.compute_intersection(output, transects, settings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the time-series of shoreline change along each transect\n",
    "\n",
    "We can keep the plot settings for a great deal, since it is usefull. \n",
    "\n",
    "**Tweak:** expand the timeseries with the BFAST algorithm (unfortunately only available in R), to study the time series and the signal decomposition.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "fig = plt.figure()\n",
    "gs = gridspec.GridSpec(len(cross_distance),1)\n",
    "gs.update(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.05)\n",
    "for i,key in enumerate(cross_distance.keys()):\n",
    "    if np.all(np.isnan(cross_distance[key])):\n",
    "        continue\n",
    "    ax = fig.add_subplot(gs[i,0])\n",
    "    ax.grid(linestyle=':', color='0.5')\n",
    "    ax.set_ylim([-50,50])\n",
    "    ax.plot(output['dates'], cross_distance[key]- np.nanmedian(cross_distance[key]), '-^', markersize=6)\n",
    "    ax.set_ylabel('distance [m]', fontsize=12)\n",
    "    ax.text(0.5,0.95, key, bbox=dict(boxstyle=\"square\", ec='k',fc='w'), ha='center',\n",
    "            va='top', transform=ax.transAxes, fontsize=14)\n",
    "mng = plt.get_current_fig_manager()                                         \n",
    "mng.window.showMaximized()    \n",
    "fig.set_size_inches([15.76,  8.52])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
